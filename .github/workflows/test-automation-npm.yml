name: Schengen Calculator Test Automation (npm)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test-accuracy:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x, 22.x]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        
    - name: Install dependencies
      run: |
        # Try npm ci first, fallback to npm install if lockfile is out of sync
        if ! npm ci; then
          echo "npm ci failed, trying npm install to regenerate lockfile..."
          npm install
        fi
      
    - name: Run accuracy tests
      run: |
        # Run tests and save logs
        npm run test 2>&1 | tee test-accuracy-${{ matrix.node-version }}.log
        # Ensure we exit with the correct status
        exit ${PIPESTATUS[0]}
      
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-accuracy-results-node-${{ matrix.node-version }}
        path: |
          test/
          *.log
          test-accuracy-${{ matrix.node-version }}.log

  eu-compliance-check:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: |
        # Try npm ci first, fallback to npm install if lockfile is out of sync
        if ! npm ci; then
          echo "npm ci failed, trying npm install to regenerate lockfile..."
          npm install
        fi
      
    - name: Run EU compliance validation
      run: |
        # Run EU compliance tests and save logs
        npm run test:eu 2>&1 | tee eu-compliance-report.txt
        exit ${PIPESTATUS[0]}
        
    - name: Check EU compliance status
      run: |
        if grep -q "âŒ" eu-compliance-report.txt; then
          echo "EU compliance tests failed"
          exit 1
        elif grep -q "âœ…" eu-compliance-report.txt; then
          echo "EU compliance tests passed"
        else
          echo "No clear test results found"
          exit 1
        fi
        
    - name: Upload EU compliance report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: eu-compliance-report
        path: eu-compliance-report.txt

  edge-case-validation:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: |
        # Try npm ci first, fallback to npm install if lockfile is out of sync
        if ! npm ci; then
          echo "npm ci failed, trying npm install to regenerate lockfile..."
          npm install
        fi
      
    - name: Run edge case tests
      run: |
        # Run edge case tests and save logs
        npm run test:edge 2>&1 | tee edge-case-report.txt
        exit ${PIPESTATUS[0]}
        
    - name: Check edge case status
      run: |
        if grep -q "âŒ" edge-case-report.txt; then
          echo "Edge case tests failed"
          exit 1
        elif grep -q "âœ…" edge-case-report.txt; then
          echo "Edge case tests passed"
        else
          echo "No clear test results found"
          exit 1
        fi
        
    - name: Upload edge case report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: edge-case-report
        path: edge-case-report.txt

  performance-benchmark:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: |
        # Try npm ci first, fallback to npm install if lockfile is out of sync
        if ! npm ci; then
          echo "npm ci failed, trying npm install to regenerate lockfile..."
          npm install
        fi
      
    - name: Run performance benchmarks
      run: |
        # Run performance benchmarks and save logs
        npm run benchmark 2>&1 | tee performance-log.txt
        exit ${PIPESTATUS[0]}
        
    - name: Analyze performance results
      run: |
        echo "Performance Analysis:"
        grep -E "(Performance:|ms|PASS|FAIL)" performance-log.txt || echo "No performance data found"
        
    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-results
        path: performance-log.txt

  test-summary:
    runs-on: ubuntu-latest
    needs: [test-accuracy, eu-compliance-check, edge-case-validation, performance-benchmark]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      
    - name: Generate test summary
      run: |
        echo "# ðŸ§ª Schengen Calculator Test Summary" > test-summary.md
        echo "" >> test-summary.md
        echo "**Generated:** $(date -u)" >> test-summary.md
        echo "**Workflow:** ${{ github.workflow }}" >> test-summary.md
        echo "**Run:** ${{ github.run_number }}" >> test-summary.md
        echo "" >> test-summary.md
        echo "## ðŸ“Š Test Results Overview" >> test-summary.md
        echo "" >> test-summary.md
        
        # Initialize counters
        TOTAL_TESTS=0
        PASSED_TESTS=0
        FAILED_TESTS=0
        
        # Check accuracy tests across all Node.js versions
        echo "### ðŸŽ¯ Accuracy Tests" >> test-summary.md
        for version in 18.x 20.x 22.x; do
          if ls test-accuracy-results-node-${version}/ 2>/dev/null | grep -q "test-accuracy-${version}.log"; then
            if grep -q "âœ… PASS" test-accuracy-results-node-${version}/test-accuracy-${version}.log; then
              echo "- âœ… Node.js ${version}: PASSED" >> test-summary.md
              ((PASSED_TESTS++))
            else
              echo "- âŒ Node.js ${version}: FAILED" >> test-summary.md
              ((FAILED_TESTS++))
            fi
            ((TOTAL_TESTS++))
          else
            echo "- âš ï¸ Node.js ${version}: NO RESULTS" >> test-summary.md
            ((FAILED_TESTS++))
            ((TOTAL_TESTS++))
          fi
        done
        echo "" >> test-summary.md
        
        # Check EU compliance
        echo "### ðŸ‡ªðŸ‡º EU Compliance" >> test-summary.md
        if [ -f eu-compliance-report/eu-compliance-report.txt ]; then
          if grep -q "âœ…" eu-compliance-report/eu-compliance-report.txt; then
            echo "- âœ… EU Official Test Cases: PASSED" >> test-summary.md
            ((PASSED_TESTS++))
          else
            echo "- âŒ EU Official Test Cases: FAILED" >> test-summary.md
            ((FAILED_TESTS++))
          fi
          ((TOTAL_TESTS++))
        else
          echo "- âš ï¸ EU Official Test Cases: NO RESULTS" >> test-summary.md
          ((FAILED_TESTS++))
          ((TOTAL_TESTS++))
        fi
        echo "" >> test-summary.md
        
        # Check edge cases
        echo "### ðŸ”§ Edge Case Validation" >> test-summary.md
        if [ -f edge-case-report/edge-case-report.txt ]; then
          if grep -q "âœ…" edge-case-report/edge-case-report.txt; then
            echo "- âœ… Edge Case Handling: PASSED" >> test-summary.md
            ((PASSED_TESTS++))
          else
            echo "- âŒ Edge Case Handling: FAILED" >> test-summary.md
            ((FAILED_TESTS++))
          fi
          ((TOTAL_TESTS++))
        else
          echo "- âš ï¸ Edge Case Handling: NO RESULTS" >> test-summary.md
          ((FAILED_TESTS++))
          ((TOTAL_TESTS++))
        fi
        echo "" >> test-summary.md
        
        # Check performance
        echo "### âš¡ Performance Benchmarks" >> test-summary.md
        if [ -f performance-results/performance-log.txt ]; then
          if grep -q "âœ…" performance-results/performance-log.txt; then
            echo "- âœ… Performance Tests: PASSED" >> test-summary.md
            ((PASSED_TESTS++))
          else
            echo "- âš ï¸ Performance Tests: CHECK REQUIRED" >> test-summary.md
            ((FAILED_TESTS++))
          fi
          ((TOTAL_TESTS++))
        else
          echo "- âš ï¸ Performance Tests: NO RESULTS" >> test-summary.md
          ((FAILED_TESTS++))
          ((TOTAL_TESTS++))
        fi
        echo "" >> test-summary.md
        
        # Overall summary
        echo "## ðŸ“ˆ Summary" >> test-summary.md
        echo "" >> test-summary.md
        echo "| Metric | Value |" >> test-summary.md
        echo "|--------|-------|" >> test-summary.md
        echo "| Total Tests | ${TOTAL_TESTS} |" >> test-summary.md
        echo "| Passed | ${PASSED_TESTS} |" >> test-summary.md
        echo "| Failed | ${FAILED_TESTS} |" >> test-summary.md
        
        if [ $TOTAL_TESTS -gt 0 ]; then
          PASS_RATE=$((PASSED_TESTS * 100 / TOTAL_TESTS))
          echo "| Pass Rate | ${PASS_RATE}% |" >> test-summary.md
        else
          echo "| Pass Rate | N/A |" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        
        # Final status
        if [ $FAILED_TESTS -eq 0 ] && [ $TOTAL_TESTS -gt 0 ]; then
          echo "ðŸŽ‰ **All tests passed successfully!**" >> test-summary.md
        elif [ $TOTAL_TESTS -eq 0 ]; then
          echo "âš ï¸ **No test results found - check workflow execution**" >> test-summary.md
        else
          echo "âŒ **Some tests failed - review results above**" >> test-summary.md
        fi
        
        echo "" >> test-summary.md
        echo "---" >> test-summary.md
        echo "*Generated by GitHub Actions on $(date -u)*" >> test-summary.md
        
        cat test-summary.md
        
    - name: Upload test summary
      uses: actions/upload-artifact@v4
      with:
        name: test-summary
        path: test-summary.md